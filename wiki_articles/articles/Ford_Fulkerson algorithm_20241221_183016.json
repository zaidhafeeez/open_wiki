{
  "title": "Ford–Fulkerson algorithm",
  "summary": "The Ford–Fulkerson method or Ford–Fulkerson algorithm (FFA) is a greedy algorithm that computes the maximum flow in a flow network. It is sometimes called a \"method\" instead of an \"algorithm\" as the approach to finding augmenting paths in a residual graph is not fully specified or it is specified in several implementations with different running times. It was published in 1956 by L. R. Ford Jr. and D. R. Fulkerson. The name \"Ford–Fulkerson\" is often also used for the Edmonds–Karp algorithm, whic",
  "content": "---\ntitle: Ford–Fulkerson algorithm\nurl: https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm\nlanguage: en\ncategories: [\"Category:All Wikipedia articles written in American English\", \"Category:Articles with example Python (programming language) code\", \"Category:Articles with example pseudocode\", \"Category:Articles with short description\", \"Category:CS1 maint: multiple names: authors list\", \"Category:Commons category link from Wikidata\", \"Category:Graph algorithms\", \"Category:Network flow problem\", \"Category:Short description is different from Wikidata\", \"Category:Use American English from April 2019\"]\nreferences: 0\nlast_modified: 2024-12-19T13:42:22Z\n---\n\n# Ford–Fulkerson algorithm\n\n## Summary\n\nThe Ford–Fulkerson method or Ford–Fulkerson algorithm (FFA) is a greedy algorithm that computes the maximum flow in a flow network. It is sometimes called a \"method\" instead of an \"algorithm\" as the approach to finding augmenting paths in a residual graph is not fully specified or it is specified in several implementations with different running times. It was published in 1956 by L. R. Ford Jr. and D. R. Fulkerson. The name \"Ford–Fulkerson\" is often also used for the Edmonds–Karp algorithm, whic\n\n## Full Content\n\nThe Ford–Fulkerson method or Ford–Fulkerson algorithm (FFA) is a greedy algorithm that computes the maximum flow in a flow network. It is sometimes called a \"method\" instead of an \"algorithm\" as the approach to finding augmenting paths in a residual graph is not fully specified or it is specified in several implementations with different running times. It was published in 1956 by L. R. Ford Jr. and D. R. Fulkerson. The name \"Ford–Fulkerson\" is often also used for the Edmonds–Karp algorithm, which is a fully defined implementation of the Ford–Fulkerson method.\nThe idea behind the algorithm is as follows: as long as there is a path from the source (start node) to the sink (end node), with available capacity on all edges in the path, we send flow along one of the paths. Then we find another path, and so on. A path with available capacity is called an augmenting path.\n\nAlgorithm\nLet \n  \n    \n      \n        G\n        (\n        V\n        ,\n        E\n        )\n      \n    \n    {\\displaystyle G(V,E)}\n  \n be a graph, and for each edge from u to v, let \n  \n    \n      \n        c\n        (\n        u\n        ,\n        v\n        )\n      \n    \n    {\\displaystyle c(u,v)}\n  \n be the capacity and \n  \n    \n      \n        f\n        (\n        u\n        ,\n        v\n        )\n      \n    \n    {\\displaystyle f(u,v)}\n  \n be the flow. We want to find the maximum flow from the source s to the sink t. After every step in the algorithm the following is maintained:\n\nThis means that the flow through the network is a legal flow after each round in the algorithm. We define the residual network \n  \n    \n      \n        \n          G\n          \n            f\n          \n        \n        (\n        V\n        ,\n        \n          E\n          \n            f\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{f}(V,E_{f})}\n  \n to be the network with capacity \n  \n    \n      \n        \n          c\n          \n            f\n          \n        \n        (\n        u\n        ,\n        v\n        )\n        =\n        c\n        (\n        u\n        ,\n        v\n        )\n        −\n        f\n        (\n        u\n        ,\n        v\n        )\n      \n    \n    {\\displaystyle c_{f}(u,v)=c(u,v)-f(u,v)}\n  \n and no flow. Notice that it can happen that a flow from v to u is allowed in the residual\nnetwork, though disallowed in the original network: if \n  \n    \n      \n        f\n        (\n        u\n        ,\n        v\n        )\n        >\n        0\n      \n    \n    {\\displaystyle f(u,v)>0}\n  \n and \n  \n    \n      \n        c\n        (\n        v\n        ,\n        u\n        )\n        =\n        0\n      \n    \n    {\\displaystyle c(v,u)=0}\n  \n then \n  \n    \n      \n        \n          c\n          \n            f\n          \n        \n        (\n        v\n        ,\n        u\n        )\n        =\n        c\n        (\n        v\n        ,\n        u\n        )\n        −\n        f\n        (\n        v\n        ,\n        u\n        )\n        =\n        f\n        (\n        u\n        ,\n        v\n        )\n        >\n        0\n      \n    \n    {\\displaystyle c_{f}(v,u)=c(v,u)-f(v,u)=f(u,v)>0}\n  \n.\n\nThe path in step 2 can be found with, for example, breadth-first search (BFS) or depth-first search in \n  \n    \n      \n        \n          G\n          \n            f\n          \n        \n        (\n        V\n        ,\n        \n          E\n          \n            f\n          \n        \n        )\n      \n    \n    {\\displaystyle G_{f}(V,E_{f})}\n  \n. The former is known as the Edmonds–Karp algorithm.\nWhen no more paths in step 2 can be found, s will not be able to reach t in the residual\nnetwork. If S is the set of nodes reachable by s in the residual network, then the total\ncapacity in the original network of edges from S to the remainder of V is on the one hand\nequal to the total flow we found from s to t,\nand on the other hand serves as an upper bound for all such flows.\nThis proves that the flow we found is maximal. See also Max-flow Min-cut theorem.\nIf the graph \n  \n    \n      \n        G\n        (\n        V\n        ,\n        E\n        )\n      \n    \n    {\\displaystyle G(V,E)}\n  \n has multiple sources and sinks, we act as follows:\nSuppose that \n  \n    \n      \n        T\n        =\n        {\n        t\n        ∣\n        t\n        \n           is a sink\n        \n        }\n      \n    \n    {\\displaystyle T=\\{t\\mid t{\\text{ is a sink}}\\}}\n  \n and \n  \n    \n      \n        S\n        =\n        {\n        s\n        ∣\n        s\n        \n           is a source\n        \n        }\n      \n    \n    {\\displaystyle S=\\{s\\mid s{\\text{ is a source}}\\}}\n  \n. Add a new source \n  \n    \n      \n        \n          s\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle s^{*}}\n  \n with an edge \n  \n    \n      \n        (\n        \n          s\n          \n            ∗\n          \n        \n        ,\n        s\n        )\n      \n    \n    {\\displaystyle (s^{*},s)}\n  \n from \n  \n    \n      \n        \n          s\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle s^{*}}\n  \n to every node \n  \n    \n      \n        s\n        ∈\n        S\n      \n    \n    {\\displaystyle s\\in S}\n  \n, with capacity \n  \n    \n      \n        c\n        (\n        \n          s\n          \n            ∗\n          \n        \n        ,\n        s\n        )\n        =\n        \n          d\n          \n            s\n          \n        \n        =\n        \n          ∑\n          \n            (\n            s\n            ,\n            u\n            )\n            ∈\n            E\n          \n        \n        c\n        (\n        s\n        ,\n        u\n        )\n      \n    \n    {\\displaystyle c(s^{*},s)=d_{s}=\\sum _{(s,u)\\in E}c(s,u)}\n  \n. And add a new sink \n  \n    \n      \n        \n          t\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle t^{*}}\n  \n with an edge \n  \n    \n      \n        (\n        t\n        ,\n        \n          t\n          \n            ∗\n          \n        \n        )\n      \n    \n    {\\displaystyle (t,t^{*})}\n  \n from every node \n  \n    \n      \n        t\n        ∈\n        T\n      \n    \n    {\\displaystyle t\\in T}\n  \n to \n  \n    \n      \n        \n          t\n          \n            ∗\n          \n        \n      \n    \n    {\\displaystyle t^{*}}\n  \n, with capacity \n  \n    \n      \n        c\n        (\n        t\n        ,\n        \n          t\n          \n            ∗\n          \n        \n        )\n        =\n        \n          d\n          \n            t\n          \n        \n        =\n        \n          ∑\n          \n            (\n            v\n            ,\n            t\n            )\n            ∈\n            E\n          \n        \n        c\n        (\n        v\n        ,\n        t\n        )\n      \n    \n    {\\displaystyle c(t,t^{*})=d_{t}=\\sum _{(v,t)\\in E}c(v,t)}\n  \n. Then apply the Ford–Fulkerson algorithm.\n\nAlso, if a node u has capacity constraint \n  \n    \n      \n        \n          d\n          \n            u\n          \n        \n      \n    \n    {\\displaystyle d_{u}}\n  \n, we replace this node with two nodes \n  \n    \n      \n        \n          u\n          \n            \n              i\n              n\n            \n          \n        \n        ,\n        \n          u\n          \n            \n              o\n              u\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle u_{\\mathrm {in} },u_{\\mathrm {out} }}\n  \n, and an edge \n  \n    \n      \n        (\n        \n          u\n          \n            \n              i\n              n\n            \n          \n        \n        ,\n        \n          u\n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle (u_{\\mathrm {in} },u_{\\mathrm {out} })}\n  \n, with capacity \n  \n    \n      \n        c\n        (\n        \n          u\n          \n            \n              i\n              n\n            \n          \n        \n        ,\n        \n          u\n          \n            \n              o\n              u\n              t\n            \n          \n        \n        )\n        =\n        \n          d\n          \n            u\n          \n        \n      \n    \n    {\\displaystyle c(u_{\\mathrm {in} },u_{\\mathrm {out} })=d_{u}}\n  \n. Then apply the Ford–Fulkerson algorithm.\n\nComplexity\nBy adding the flow augmenting path to the flow already established in the graph, the maximum flow will be reached when no more flow augmenting paths can be found in the graph.  However, there is no certainty that this situation will ever be reached, so the best that can be guaranteed is that the answer will be correct if the algorithm terminates.  In the case that the algorithm runs forever, the flow might not even converge towards the maximum flow.  However, this situation only occurs with irrational flow values.  When the capacities are integers, the runtime of Ford–Fulkerson is bounded by \n  \n    \n      \n        O\n        (\n        E\n        f\n        )\n      \n    \n    {\\displaystyle O(Ef)}\n  \n (see big O notation), where \n  \n    \n      \n        E\n      \n    \n    {\\displaystyle E}\n  \n is the number of edges in the graph and \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n is the maximum flow in the graph.  This is because each augmenting path can be found in \n  \n    \n      \n        O\n        (\n        E\n        )\n      \n    \n    {\\displaystyle O(E)}\n  \n time and increases the flow by an integer amount of at least \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n, with the upper bound \n  \n    \n      \n        f\n      \n    \n    {\\displaystyle f}\n  \n.\nA variation of the Ford–Fulkerson algorithm with guaranteed termination and a runtime independent of the maximum flow value is the Edmonds–Karp algorithm, which runs in \n  \n    \n      \n        O\n        (\n        V\n        \n          E\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle O(VE^{2})}\n  \n time.\n\nInteger flow example\nThe following example shows the first steps of Ford–Fulkerson in a flow network with 4 nodes, source \n  \n    \n      \n        A\n      \n    \n    {\\displaystyle A}\n  \n and sink \n  \n    \n      \n        D\n      \n    \n    {\\displaystyle D}\n  \n. This example shows the worst-case behaviour of the algorithm. In each step, only a flow of \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n is sent across the network. If breadth-first-search were used instead, only two steps would be needed.\n\nNon-terminating example\nConsider the flow network shown on the right, with source \n  \n    \n      \n        s\n      \n    \n    {\\displaystyle s}\n  \n, sink \n  \n    \n      \n        t\n      \n    \n    {\\displaystyle t}\n  \n, capacities of edges \n  \n    \n      \n        \n          e\n          \n            1\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle e_{1}=1}\n  \n, \n  \n    \n      \n        \n          e\n          \n            2\n          \n        \n        =\n        r\n        =\n        (\n        \n          \n            5\n          \n        \n        −\n        1\n        )\n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle e_{2}=r=({\\sqrt {5}}-1)/2}\n  \n and \n  \n    \n      \n        \n          e\n          \n            3\n          \n        \n        =\n        1\n      \n    \n    {\\displaystyle e_{3}=1}\n  \n, and the capacity of all other edges some integer \n  \n    \n      \n        M\n        ≥\n        2\n      \n    \n    {\\displaystyle M\\geq 2}\n  \n. The constant \n  \n    \n      \n        r\n      \n    \n    {\\displaystyle r}\n  \n was chosen so, that \n  \n    \n      \n        \n          r\n          \n            2\n          \n        \n        =\n        1\n        −\n        r\n      \n    \n    {\\displaystyle r^{2}=1-r}\n  \n. We use augmenting paths according to the following table, where \n  \n    \n      \n        \n          p\n          \n            1\n          \n        \n        =\n        {\n        s\n        ,\n        \n          v\n          \n            4\n          \n        \n        ,\n        \n          v\n          \n            3\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          v\n          \n            1\n          \n        \n        ,\n        t\n        }\n      \n    \n    {\\displaystyle p_{1}=\\{s,v_{4},v_{3},v_{2},v_{1},t\\}}\n  \n, \n  \n    \n      \n        \n          p\n          \n            2\n          \n        \n        =\n        {\n        s\n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          v\n          \n            3\n          \n        \n        ,\n        \n          v\n          \n            4\n          \n        \n        ,\n        t\n        }\n      \n    \n    {\\displaystyle p_{2}=\\{s,v_{2},v_{3},v_{4},t\\}}\n  \n and \n  \n    \n      \n        \n          p\n          \n            3\n          \n        \n        =\n        {\n        s\n        ,\n        \n          v\n          \n            1\n          \n        \n        ,\n        \n          v\n          \n            2\n          \n        \n        ,\n        \n          v\n          \n            3\n          \n        \n        ,\n        t\n        }\n      \n    \n    {\\displaystyle p_{3}=\\{s,v_{1},v_{2},v_{3},t\\}}\n  \n.\n\nNote that after step 1 as well as after step 5, the residual capacities of edges \n  \n    \n      \n        \n          e\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle e_{1}}\n  \n, \n  \n    \n      \n        \n          e\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle e_{2}}\n  \n and \n  \n    \n      \n        \n          e\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle e_{3}}\n  \n are in the form \n  \n    \n      \n        \n          r\n          \n            n\n          \n        \n      \n    \n    {\\displaystyle r^{n}}\n  \n, \n  \n    \n      \n        \n          r\n          \n            n\n            +\n            1\n          \n        \n      \n    \n    {\\displaystyle r^{n+1}}\n  \n and \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n, respectively, for some \n  \n    \n      \n        n\n        ∈\n        \n          N\n        \n      \n    \n    {\\displaystyle n\\in \\mathbb {N} }\n  \n. This means that we can use augmenting paths \n  \n    \n      \n        \n          p\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle p_{1}}\n  \n, \n  \n    \n      \n        \n          p\n          \n            2\n          \n        \n      \n    \n    {\\displaystyle p_{2}}\n  \n, \n  \n    \n      \n        \n          p\n          \n            1\n          \n        \n      \n    \n    {\\displaystyle p_{1}}\n  \n and \n  \n    \n      \n        \n          p\n          \n            3\n          \n        \n      \n    \n    {\\displaystyle p_{3}}\n  \n infinitely many times and residual capacities of these edges will always be in the same form. Total flow in the network after step 5 is \n  \n    \n      \n        1\n        +\n        2\n        (\n        \n          r\n          \n            1\n          \n        \n        +\n        \n          r\n          \n            2\n          \n        \n        )\n      \n    \n    {\\displaystyle 1+2(r^{1}+r^{2})}\n  \n. If we continue to use augmenting paths as above, the total flow converges to \n  \n    \n      \n        \n          1\n          +\n          2\n          \n            ∑\n            \n              i\n              =\n              1\n            \n            \n              ∞\n            \n          \n          \n            r\n            \n              i\n            \n          \n          =\n          3\n          +\n          2\n          r\n        \n      \n    \n    {\\displaystyle \\textstyle 1+2\\sum _{i=1}^{\\infty }r^{i}=3+2r}\n  \n.  However, note that there is a flow of value \n  \n    \n      \n        2\n        M\n        +\n        1\n      \n    \n    {\\displaystyle 2M+1}\n  \n, by sending \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n units of flow along \n  \n    \n      \n        s\n        \n          v\n          \n            1\n          \n        \n        t\n      \n    \n    {\\displaystyle sv_{1}t}\n  \n, 1 unit of flow along \n  \n    \n      \n        s\n        \n          v\n          \n            2\n          \n        \n        \n          v\n          \n            3\n          \n        \n        t\n      \n    \n    {\\displaystyle sv_{2}v_{3}t}\n  \n, and \n  \n    \n      \n        M\n      \n    \n    {\\displaystyle M}\n  \n units of flow along \n  \n    \n      \n        s\n        \n          v\n          \n            4\n          \n        \n        t\n      \n    \n    {\\displaystyle sv_{4}t}\n  \n. Therefore, the algorithm never terminates and the flow does not even converge to the maximum flow.\nAnother non-terminating example based on the Euclidean algorithm is given by Backman & Huynh (2018), where they also show that the worst case running-time of the Ford-Fulkerson algorithm on a network \n  \n    \n      \n        G\n        (\n        V\n        ,\n        E\n        )\n      \n    \n    {\\displaystyle G(V,E)}\n  \n in ordinal numbers is \n  \n    \n      \n        \n          ω\n          \n            Θ\n            (\n            \n              |\n            \n            E\n            \n              |\n            \n            )\n          \n        \n      \n    \n    {\\displaystyle \\omega ^{\\Theta (|E|)}}\n  \n.\n\nPython implementation of the Edmonds–Karp algorithm\nSee also\nBerge's theorem\nApproximate max-flow min-cut theorem\nTurn restriction routing\nDinic's algorithm\n\nNotes\nReferences\nCormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2001). \"Section 26.2: The Ford–Fulkerson method\". Introduction to Algorithms (Second ed.). MIT Press and McGraw–Hill. pp. 651–664. ISBN 0-262-03293-7.\nGeorge T. Heineman; Gary Pollice; Stanley Selkow (2008). \"Chapter 8:Network Flow Algorithms\". Algorithms in a Nutshell. Oreilly Media. pp. 226–250. ISBN 978-0-596-51624-6.\nJon Kleinberg; Éva Tardos (2006). \"Chapter 7:Extensions to the Maximum-Flow Problem\". Algorithm Design. Pearson Education. pp. 378–384. ISBN 0-321-29535-8.\nSamuel Gutekunst (2019). ENGRI 1101. Cornell University.\nBackman, Spencer; Huynh, Tony (2018). \"Transfinite Ford–Fulkerson on a finite network\". Computability. 7 (4): 341–347. arXiv:1504.04363. doi:10.3233/COM-180082. S2CID 15497138.\n\nExternal links\nA tutorial explaining the Ford–Fulkerson method to solve the max-flow problem\nAnother Java animation\nJava Web Start application\n Media related to Ford-Fulkerson's algorithm at Wikimedia Commons\n",
  "categories": [
    "Category:All Wikipedia articles written in American English",
    "Category:Articles with example Python (programming language) code",
    "Category:Articles with example pseudocode",
    "Category:Articles with short description",
    "Category:CS1 maint: multiple names: authors list",
    "Category:Commons category link from Wikidata",
    "Category:Graph algorithms",
    "Category:Network flow problem",
    "Category:Short description is different from Wikidata",
    "Category:Use American English from April 2019"
  ],
  "archived_date": "20241221_183016",
  "source_url": "https://en.wikipedia.org/wiki/Ford%E2%80%93Fulkerson_algorithm"
}