{
  "title": "Zero-truncated Poisson distribution",
  "summary": "In probability theory, the zero-truncated Poisson distribution (ZTP distribution) is a certain discrete probability distribution whose support is the set of positive integers.  This distribution is also known as the conditional Poisson distribution or the positive Poisson distribution. It is the conditional probability distribution of a Poisson-distributed random variable, given that the value of the random variable is not zero. Thus it is impossible for a ZTP random variable to be zero. Conside",
  "content": "---\ntitle: Zero-truncated Poisson distribution\nurl: https://en.wikipedia.org/wiki/Zero-truncated_Poisson_distribution\nlanguage: en\ncategories: [\"Category:All articles needing additional references\", \"Category:Articles needing additional references from August 2013\", \"Category:Articles with example Python (programming language) code\", \"Category:Articles with short description\", \"Category:Discrete distributions\", \"Category:Poisson distribution\", \"Category:Short description is different from Wikidata\"]\nreferences: 0\nlast_modified: 2024-12-19T14:36:47Z\n---\n\n# Zero-truncated Poisson distribution\n\n## Summary\n\nIn probability theory, the zero-truncated Poisson distribution (ZTP distribution) is a certain discrete probability distribution whose support is the set of positive integers.  This distribution is also known as the conditional Poisson distribution or the positive Poisson distribution. It is the conditional probability distribution of a Poisson-distributed random variable, given that the value of the random variable is not zero. Thus it is impossible for a ZTP random variable to be zero. Conside\n\n## Full Content\n\nIn probability theory, the zero-truncated Poisson distribution (ZTP distribution) is a certain discrete probability distribution whose support is the set of positive integers.  This distribution is also known as the conditional Poisson distribution or the positive Poisson distribution. It is the conditional probability distribution of a Poisson-distributed random variable, given that the value of the random variable is not zero. Thus it is impossible for a ZTP random variable to be zero. Consider for example the random variable of the number of items in a shopper's basket at a supermarket checkout line.  Presumably a shopper does not stand in line with nothing to buy (i.e., the minimum purchase is 1 item), so this phenomenon may follow a ZTP distribution.\nSince the ZTP is a truncated distribution with the truncation stipulated as k > 0, one can derive the probability mass function g(k;λ) from a standard Poisson distribution f(k;λ) as follows:\n\n  \n    \n      \n        g\n        (\n        k\n        ;\n        λ\n        )\n        =\n        P\n        (\n        X\n        =\n        k\n        ∣\n        X\n        >\n        0\n        )\n        =\n        \n          \n            \n              f\n              (\n              k\n              ;\n              λ\n              )\n            \n            \n              1\n              −\n              f\n              (\n              0\n              ;\n              λ\n              )\n            \n          \n        \n        =\n        \n          \n            \n              \n                λ\n                \n                  k\n                \n              \n              \n                e\n                \n                  −\n                  λ\n                \n              \n            \n            \n              k\n              !\n              \n                (\n                \n                  1\n                  −\n                  \n                    e\n                    \n                      −\n                      λ\n                    \n                  \n                \n                )\n              \n            \n          \n        \n        =\n        \n          \n            \n              λ\n              \n                k\n              \n            \n            \n              (\n              \n                e\n                \n                  λ\n                \n              \n              −\n              1\n              )\n              k\n              !\n            \n          \n        \n      \n    \n    {\\displaystyle g(k;\\lambda )=P(X=k\\mid X>0)={\\frac {f(k;\\lambda )}{1-f(0;\\lambda )}}={\\frac {\\lambda ^{k}e^{-\\lambda }}{k!\\left(1-e^{-\\lambda }\\right)}}={\\frac {\\lambda ^{k}}{(e^{\\lambda }-1)k!}}}\n  \n\nThe mean is\n\n  \n    \n      \n        E\n        ⁡\n        [\n        X\n        ]\n        =\n        \n          \n            λ\n            \n              1\n              −\n              \n                e\n                \n                  −\n                  λ\n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              λ\n              \n                e\n                \n                  λ\n                \n              \n            \n            \n              \n                e\n                \n                  λ\n                \n              \n              −\n              1\n            \n          \n        \n      \n    \n    {\\displaystyle \\operatorname {E} [X]={\\frac {\\lambda }{1-e^{-\\lambda }}}={\\frac {\\lambda e^{\\lambda }}{e^{\\lambda }-1}}}\n  \n\nand the variance is\n\n  \n    \n      \n        Var\n        ⁡\n        [\n        X\n        ]\n        =\n        \n          \n            \n              λ\n              +\n              \n                λ\n                \n                  2\n                \n              \n            \n            \n              1\n              −\n              \n                e\n                \n                  −\n                  λ\n                \n              \n            \n          \n        \n        −\n        \n          \n            \n              λ\n              \n                2\n              \n            \n            \n              (\n              1\n              −\n              \n                e\n                \n                  −\n                  λ\n                \n              \n              \n                )\n                \n                  2\n                \n              \n            \n          \n        \n        =\n        E\n        ⁡\n        [\n        X\n        ]\n        (\n        1\n        +\n        λ\n        −\n        E\n        ⁡\n        [\n        X\n        ]\n        )\n      \n    \n    {\\displaystyle \\operatorname {Var} [X]={\\frac {\\lambda +\\lambda ^{2}}{1-e^{-\\lambda }}}-{\\frac {\\lambda ^{2}}{(1-e^{-\\lambda })^{2}}}=\\operatorname {E} [X](1+\\lambda -\\operatorname {E} [X])}\n\nParameter estimation\nThe method of moments estimator \n  \n    \n      \n        \n          \n            \n              λ\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\widehat {\\lambda }}}\n  \n for the parameter \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n is obtained by solving\n\n  \n    \n      \n        \n          \n            \n              \n                λ\n                ^\n              \n            \n            \n              1\n              −\n              \n                e\n                \n                  −\n                  \n                    \n                      \n                        λ\n                        ^\n                      \n                    \n                  \n                \n              \n            \n          \n        \n        =\n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\frac {\\widehat {\\lambda }}{1-e^{-{\\widehat {\\lambda }}}}}={\\bar {x}}}\n  \n\nwhere \n  \n    \n      \n        \n          \n            \n              x\n              ¯\n            \n          \n        \n      \n    \n    {\\displaystyle {\\bar {x}}}\n  \n is the sample mean.\nThis equation has a solution in terms of the Lambert W function. In practice, a solution may be found using numerical methods.\n\nExamples\nInsurance claims:\nImagine navigating the intricate landscape of auto insurance claims, where each claim signifies a unique event – an accident or damage occurrence. The ZTP distribution seamlessly aligns with this scenario, excluding the possibility of policyholders with zero claims.\nLet X denote the random variable representing the number of insurance claims. If λ is the average rate of claims, the ZTP probability mass function takes the form:\n\n  \n    \n      \n        P\n        (\n        X\n        =\n        k\n        )\n        =\n        \n          \n            \n              \n                λ\n                \n                  k\n                \n              \n              \n                e\n                \n                  −\n                  λ\n                \n              \n            \n            \n              k\n              !\n              \n                (\n                \n                  1\n                  −\n                  \n                    e\n                    \n                      −\n                      λ\n                    \n                  \n                \n                )\n              \n            \n          \n        \n      \n    \n    {\\displaystyle P(X=k)={\\frac {\\lambda ^{k}e^{-\\lambda }}{k!\\left(1-e^{-\\lambda }\\right)}}}\n  \n for k= 1,2,3,...\nThis formula encapsulates the probability of observing k claims given that at least one claim has transpired. The denominator ensures the exclusion of the improbable zero-claim scenario. By utilizing the zero-truncated Poisson distribution, the manufacturing company can analyze and predict the frequency of defects in their products while focusing on instances where defects exist. This distribution helps in understanding and improving the quality control process, especially when it's crucial to account for at least one defect.\n\nGenerating zero-truncated Poisson-distributed random variables\nRandom variables sampled from the zero-truncated Poisson distribution may be achieved using algorithms derived from Poisson distribution sampling algorithms.\n\ninit:\n    Let k ← 1, t ← e−λ / (1 - e−λ) * λ, s ← t.\n    Generate uniform random number u in [0,1].\nwhile s < u do:\n    k ← k + 1.\n    t ← t * λ / k.\n    s ← s + t.\nreturn k.\n\nThe cost of the procedure above is linear in k, which may be large for large values of \n  \n    \n      \n        λ\n      \n    \n    {\\displaystyle \\lambda }\n  \n. Given access to an efficient sampler for non-truncated Poisson random variates, a non-iterative approach involves sampling from a truncated exponential distribution representing the time of the first event in a Poisson point process, conditional on such an event existing.\nA simple NumPy implementation is:\n\n\n== References ==\n",
  "categories": [
    "Category:All articles needing additional references",
    "Category:Articles needing additional references from August 2013",
    "Category:Articles with example Python (programming language) code",
    "Category:Articles with short description",
    "Category:Discrete distributions",
    "Category:Poisson distribution",
    "Category:Short description is different from Wikidata"
  ],
  "archived_date": "20241221_183018",
  "source_url": "https://en.wikipedia.org/wiki/Zero-truncated_Poisson_distribution"
}