{
  "title": "Machine epsilon",
  "summary": "Machine epsilon or machine precision is an upper bound on the relative approximation error due to rounding in floating point number systems. This value characterizes computer arithmetic in the field of numerical analysis, and by extension in the subject of computational science. The quantity is also called macheps and it has the symbols Greek epsilon \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n.\nThere are two prevailing definitions, denoted here as rounding machine ",
  "content": "---\ntitle: Machine epsilon\nurl: https://en.wikipedia.org/wiki/Machine_epsilon\nlanguage: en\ncategories: [\"Category:Articles with example C code\", \"Category:Articles with example Python (programming language) code\", \"Category:Articles with short description\", \"Category:Computer arithmetic\", \"Category:Short description is different from Wikidata\", \"Category:Wikipedia articles needing clarification from March 2021\"]\nreferences: 0\nlast_modified: 2024-12-19T13:52:02Z\n---\n\n# Machine epsilon\n\n## Summary\n\nMachine epsilon or machine precision is an upper bound on the relative approximation error due to rounding in floating point number systems. This value characterizes computer arithmetic in the field of numerical analysis, and by extension in the subject of computational science. The quantity is also called macheps and it has the symbols Greek epsilon \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n.\nThere are two prevailing definitions, denoted here as rounding machine \n\n## Full Content\n\nMachine epsilon or machine precision is an upper bound on the relative approximation error due to rounding in floating point number systems. This value characterizes computer arithmetic in the field of numerical analysis, and by extension in the subject of computational science. The quantity is also called macheps and it has the symbols Greek epsilon \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n.\nThere are two prevailing definitions, denoted here as rounding machine epsilon or the formal definition and interval machine epsilon or mainstream definition.\nIn the mainstream definition, machine epsilon is independent of rounding method, and is defined simply as the difference between 1 and the next larger floating point number.\nIn the formal definition, machine epsilon is dependent on the type of rounding used and is also called unit roundoff, which has the symbol bold Roman u.\nThe two terms can generally be considered to differ by simply a factor of two, with the formal definition yielding an epsilon half the size of the mainstream definition, as summarized in the tables in the next section.\n\nValues for standard hardware arithmetics\nThe following table lists machine epsilon values for standard floating-point formats.\n\nAlternative definitions for epsilon\nThe IEEE standard does not define the terms machine epsilon and unit roundoff, so differing definitions of these terms are in use, which can cause some confusion.\nThe two terms differ by simply a factor of two.  The more-widely used term (referred to as the mainstream definition in this article), is used in most modern programming languages and is simply defined as machine epsilon is the difference between 1 and the next larger floating point number.  The formal definition can generally be considered to yield an epsilon half the size of the mainstream definition, although its definition does vary depending on the form of rounding used.\nThe two terms are described at length in the next two subsections.\n\nFormal definition (Rounding machine epsilon)\nThe formal definition for machine epsilon is the one used by Prof. James Demmel in lecture scripts, the LAPACK linear algebra package, numerics research papers and some scientific computing software.  Most numerical analysts use the words machine epsilon and unit roundoff interchangeably with this meaning, which is explored in depth throughout this subsection.\nRounding is a procedure for choosing the representation of a real number in a floating point number system.  For a number system and a rounding procedure, machine epsilon is the maximum relative error of the chosen rounding procedure.\nSome background is needed to determine a value from this definition. A floating point number system is characterized by a radix which is also called the base, \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n, and by the precision \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n, i.e. the number of radix \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n digits of the significand (including any leading implicit bit). All the numbers with the same exponent, \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n  \n, have the spacing, \n  \n    \n      \n        \n          b\n          \n            e\n            −\n            (\n            p\n            −\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{e-(p-1)}}\n  \n. The spacing changes at the numbers that are perfect powers of \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n; the spacing on the side of larger magnitude is \n  \n    \n      \n        b\n      \n    \n    {\\displaystyle b}\n  \n times larger than the spacing on the side of smaller magnitude.\nSince machine epsilon is a bound for relative error, it suffices to consider numbers with exponent \n  \n    \n      \n        e\n        =\n        0\n      \n    \n    {\\displaystyle e=0}\n  \n. It also suffices to consider positive numbers. For the usual round-to-nearest kind of rounding, the absolute rounding error is at most half the spacing, or \n  \n    \n      \n        \n          b\n          \n            −\n            (\n            p\n            −\n            1\n            )\n          \n        \n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle b^{-(p-1)}/2}\n  \n. This value is the biggest possible numerator for the relative error. The denominator in the relative error is the number being rounded, which should be as small as possible to make the relative error large. The worst relative error therefore happens when rounding is applied to numbers of the form \n  \n    \n      \n        1\n        +\n        a\n      \n    \n    {\\displaystyle 1+a}\n  \n where \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n is between \n  \n    \n      \n        0\n      \n    \n    {\\displaystyle 0}\n  \n and \n  \n    \n      \n        \n          b\n          \n            −\n            (\n            p\n            −\n            1\n            )\n          \n        \n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle b^{-(p-1)}/2}\n  \n. All these numbers round to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n with relative error \n  \n    \n      \n        a\n        \n          /\n        \n        (\n        1\n        +\n        a\n        )\n      \n    \n    {\\displaystyle a/(1+a)}\n  \n. The maximum occurs when \n  \n    \n      \n        a\n      \n    \n    {\\displaystyle a}\n  \n is at the upper end of its range. The \n  \n    \n      \n        1\n        +\n        a\n      \n    \n    {\\displaystyle 1+a}\n  \n in the denominator is negligible compared to the numerator, so it is left off for expediency, and just \n  \n    \n      \n        \n          b\n          \n            −\n            (\n            p\n            −\n            1\n            )\n          \n        \n        \n          /\n        \n        2\n      \n    \n    {\\displaystyle b^{-(p-1)}/2}\n  \n is taken as machine epsilon. As has been shown here, the relative error is worst for numbers that round to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n  \n, so machine epsilon also is called unit roundoff meaning roughly \"the maximum error that can occur when rounding to the unit value\".\nThus, the maximum spacing between a normalised floating point number, \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, and an adjacent normalised number is \n  \n    \n      \n        2\n        ε\n        \n          |\n        \n        x\n        \n          |\n        \n      \n    \n    {\\displaystyle 2\\varepsilon |x|}\n  \n.\n\nArithmetic model\nNumerical analysis uses machine epsilon to study the effects of rounding error. The actual errors of machine arithmetic are far too complicated to be studied directly, so instead, the following simple model is used. The IEEE arithmetic standard says all floating-point operations are done as if it were possible to perform the infinite-precision operation, and then, the result is rounded to a floating-point number. Suppose (1) \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n, \n  \n    \n      \n        y\n      \n    \n    {\\displaystyle y}\n  \n are floating-point numbers, (2) \n  \n    \n      \n        ∙\n      \n    \n    {\\displaystyle \\bullet }\n  \n is an arithmetic operation on floating-point numbers such as addition or multiplication, and (3) \n  \n    \n      \n        ∘\n      \n    \n    {\\displaystyle \\circ }\n  \n is the infinite precision operation. According to the standard, the computer calculates:\n\n  \n    \n      \n        x\n        ∙\n        y\n        =\n        \n          \n            round\n          \n        \n        (\n        x\n        ∘\n        y\n        )\n      \n    \n    {\\displaystyle x\\bullet y={\\mbox{round}}(x\\circ y)}\n  \n\nBy the meaning of machine epsilon, the relative error of the rounding is at most machine epsilon in magnitude, so:\n\n  \n    \n      \n        x\n        ∙\n        y\n        =\n        (\n        x\n        ∘\n        y\n        )\n        (\n        1\n        +\n        z\n        )\n      \n    \n    {\\displaystyle x\\bullet y=(x\\circ y)(1+z)}\n  \n\nwhere \n  \n    \n      \n        z\n      \n    \n    {\\displaystyle z}\n  \n in absolute magnitude is at most \n  \n    \n      \n        ε\n      \n    \n    {\\displaystyle \\varepsilon }\n  \n or u. The books by Demmel and Higham in the references can be consulted to see how this model is used to analyze the errors of, say, Gaussian elimination.\n\nMainstream definition (Interval machine epsilon)\nThis alternative definition is significantly more widespread: machine epsilon is the difference between 1 and the next larger floating point number.  This definition is used in language constants in Ada, C, C++, Fortran, MATLAB, Mathematica, Octave, Pascal, Python and Rust etc., and defined in textbooks like «Numerical Recipes» by Press et al.\nBy this definition, ε equals the value of the unit in the last place relative to 1, i.e. \n  \n    \n      \n        \n          b\n          \n            −\n            (\n            p\n            −\n            1\n            )\n          \n        \n      \n    \n    {\\displaystyle b^{-(p-1)}}\n  \n (where b is the base of the floating point system and p is the precision) and the unit roundoff is u = ε / 2, assuming round-to-nearest mode, and u = ε, assuming round-by-chop.\nThe prevalence of this definition is rooted in its use in the ISO C Standard for constants relating to floating-point types and corresponding constants in other programming languages. It is also widely used in scientific computing software and in the numerics and computing literature.\n\nHow to determine machine epsilon\nWhere standard libraries do not provide precomputed values (as <float.h> does with FLT_EPSILON, DBL_EPSILON and LDBL_EPSILON for C and <limits> does with std::numeric_limits<T>::epsilon() in C++), the best way to determine machine epsilon is to refer to the table, above, and use the appropriate power formula.  Computing machine epsilon is often given as a textbook exercise. The following examples compute interval machine epsilon in the sense of the spacing of the floating point numbers at 1 rather than in the sense of the unit roundoff.\nNote that results depend on the particular floating-point format used, such as float, double, long double, or similar as supported by the programming language, the compiler, and the runtime library for the actual platform.\nSome formats supported by the processor might not be supported by the chosen compiler and operating system. Other formats might be emulated by the runtime library, including arbitrary-precision arithmetic available in some languages and libraries.\nIn a strict sense the term machine epsilon means the \n  \n    \n      \n        1\n        +\n        ε\n      \n    \n    {\\displaystyle 1+\\varepsilon }\n  \n accuracy directly supported by the processor (or coprocessor), not some \n  \n    \n      \n        1\n        +\n        ε\n      \n    \n    {\\displaystyle 1+\\varepsilon }\n  \n accuracy supported by a specific compiler for a specific operating system, unless it's known to use the best format.\nIEEE 754 floating-point formats have the property that, when reinterpreted as a two's complement integer of the same width, they monotonically increase over positive values and monotonically decrease over negative values (see the binary representation of 32 bit floats). They also have the property that \n  \n    \n      \n        0\n        <\n        \n          |\n        \n        f\n        (\n        x\n        )\n        \n          |\n        \n        <\n        ∞\n      \n    \n    {\\displaystyle 0<|f(x)|<\\infty }\n  \n, and \n  \n    \n      \n        \n          |\n        \n        f\n        (\n        x\n        +\n        1\n        )\n        −\n        f\n        (\n        x\n        )\n        \n          |\n        \n        ≥\n        \n          |\n        \n        f\n        (\n        x\n        )\n        −\n        f\n        (\n        x\n        −\n        1\n        )\n        \n          |\n        \n      \n    \n    {\\displaystyle |f(x+1)-f(x)|\\geq |f(x)-f(x-1)|}\n  \n (where \n  \n    \n      \n        f\n        (\n        x\n        )\n      \n    \n    {\\displaystyle f(x)}\n  \n is the aforementioned integer reinterpretation of \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n). In languages that allow type punning and always use IEEE 754–1985, we can exploit this to compute a machine epsilon in constant time. For example, in C:\n\nThis will give a result of the same sign as value. If a positive result is always desired, the return statement of machine_eps can be replaced with:\n\nExample in Python:\n\n64-bit doubles give 2.220446e-16, which is 2−52 as expected.\n\nApproximation\nThe following simple algorithm can be used to approximate the machine epsilon, to within a factor of two (one order of magnitude) of its true value, using a linear search.\n\nepsilon = 1.0;\n\nwhile (1.0 + 0.5 * epsilon) ≠ 1.0:\n    epsilon = 0.5 * epsilon\n\nThe machine epsilon, \n  \n    \n      \n        \n          ε\n          \n            mach\n          \n        \n      \n    \n    {\\textstyle \\varepsilon _{\\text{mach}}}\n  \n can also simply be calculated as two to the negative power of the number of bits used for the mantissa.\n\n  \n    \n      \n        \n          ε\n          \n            mach\n          \n        \n         \n        =\n         \n        \n          2\n          \n            −\n            \n              bits used for magnitude of mantissa\n            \n          \n        \n      \n    \n    {\\displaystyle \\varepsilon _{\\text{mach}}\\ =\\ 2^{-{\\text{bits used for magnitude of mantissa}}}}\n\nRelationship to absolute relative error\nIf \n  \n    \n      \n        y\n      \n    \n    {\\textstyle y}\n  \n is the machine representation of a number \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n then the absolute relative error in the representation is \n  \n    \n      \n        \n          |\n          \n            \n              \n                \n                  x\n                  −\n                  y\n                \n                x\n              \n            \n          \n          |\n        \n        ≤\n        \n          ε\n          \n            mach\n          \n        \n        .\n      \n    \n    {\\textstyle \\left|{\\dfrac {x-y}{x}}\\right|\\leq \\varepsilon _{\\text{mach}}.}\n\nProof\nThe following proof is limited to positive numbers and machine representations using round-by-chop.\nIf \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n is a positive number we want to represent, it will be between a machine number \n  \n    \n      \n        \n          x\n          \n            b\n          \n        \n      \n    \n    {\\textstyle x_{b}}\n  \n below \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n and a machine number \n  \n    \n      \n        \n          x\n          \n            u\n          \n        \n      \n    \n    {\\textstyle x_{u}}\n  \n above \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n.\nIf \n  \n    \n      \n        \n          x\n          \n            b\n          \n        \n        =\n        \n          \n            (\n            \n              1.\n              \n                b\n                \n                  1\n                \n              \n              \n                b\n                \n                  2\n                \n              \n              …\n              \n                b\n                \n                  m\n                \n              \n            \n            )\n          \n          \n            2\n          \n        \n        ×\n        \n          2\n          \n            k\n          \n        \n      \n    \n    {\\textstyle x_{b}=\\left(1.b_{1}b_{2}\\ldots b_{m}\\right)_{2}\\times 2^{k}}\n  \n, where \n  \n    \n      \n        m\n      \n    \n    {\\textstyle m}\n  \n is the number of bits used for the magnitude of the significand, then:\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  x\n                  \n                    u\n                  \n                \n              \n              \n                \n                =\n                \n                  [\n                  \n                    (\n                    1.\n                    \n                      b\n                      \n                        1\n                      \n                    \n                    \n                      b\n                      \n                        2\n                      \n                    \n                    …\n                    \n                      b\n                      \n                        m\n                      \n                    \n                    \n                      )\n                      \n                        2\n                      \n                    \n                    +\n                    (\n                    0.00\n                    …\n                    1\n                    \n                      )\n                      \n                        2\n                      \n                    \n                  \n                  ]\n                \n                ×\n                \n                  2\n                  \n                    k\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  [\n                  \n                    (\n                    1.\n                    \n                      b\n                      \n                        1\n                      \n                    \n                    \n                      b\n                      \n                        2\n                      \n                    \n                    …\n                    \n                      b\n                      \n                        m\n                      \n                    \n                    \n                      )\n                      \n                        2\n                      \n                    \n                    +\n                    \n                      2\n                      \n                        −\n                        m\n                      \n                    \n                  \n                  ]\n                \n                ×\n                \n                  2\n                  \n                    k\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                (\n                1.\n                \n                  b\n                  \n                    1\n                  \n                \n                \n                  b\n                  \n                    2\n                  \n                \n                …\n                \n                  b\n                  \n                    m\n                  \n                \n                \n                  )\n                  \n                    2\n                  \n                \n                ×\n                \n                  2\n                  \n                    k\n                  \n                \n                +\n                \n                  2\n                  \n                    −\n                    m\n                  \n                \n                ×\n                \n                  2\n                  \n                    k\n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                (\n                1.\n                \n                  b\n                  \n                    1\n                  \n                \n                \n                  b\n                  \n                    2\n                  \n                \n                …\n                \n                  b\n                  \n                    m\n                  \n                \n                \n                  )\n                  \n                    2\n                  \n                \n                ×\n                \n                  2\n                  \n                    k\n                  \n                \n                +\n                \n                  2\n                  \n                    −\n                    m\n                    +\n                    k\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}x_{u}&=\\left[(1.b_{1}b_{2}\\ldots b_{m})_{2}+(0.00\\ldots 1)_{2}\\right]\\times 2^{k}\\\\&=\\left[(1.b_{1}b_{2}\\ldots b_{m})_{2}+2^{-m}\\right]\\times 2^{k}\\\\&=(1.b_{1}b_{2}\\ldots b_{m})_{2}\\times 2^{k}+2^{-m}\\times 2^{k}\\\\&=(1.b_{1}b_{2}\\ldots b_{m})_{2}\\times 2^{k}+2^{-m+k}.\\end{aligned}}}\n  \n\nSince the representation of \n  \n    \n      \n        x\n      \n    \n    {\\textstyle x}\n  \n will be either \n  \n    \n      \n        \n          x\n          \n            b\n          \n        \n      \n    \n    {\\textstyle x_{b}}\n  \n or \n  \n    \n      \n        \n          x\n          \n            u\n          \n        \n      \n    \n    {\\textstyle x_{u}}\n  \n,\n\n  \n    \n      \n        \n          \n            \n              \n                \n                  |\n                  \n                    x\n                    −\n                    y\n                  \n                  |\n                \n              \n              \n                \n                ≤\n                \n                  |\n                  \n                    \n                      x\n                      \n                        b\n                      \n                    \n                    −\n                    \n                      x\n                      \n                        u\n                      \n                    \n                  \n                  |\n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  2\n                  \n                    −\n                    m\n                    +\n                    k\n                  \n                \n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\left|x-y\\right|&\\leq \\left|x_{b}-x_{u}\\right|\\\\&=2^{-m+k}\\end{aligned}}}\n  \n \n\n  \n    \n      \n        \n          \n            \n              \n                \n                  |\n                  \n                    \n                      \n                        x\n                        −\n                        y\n                      \n                      x\n                    \n                  \n                  |\n                \n              \n              \n                \n                ≤\n                \n                  \n                    \n                      2\n                      \n                        −\n                        m\n                        +\n                        k\n                      \n                    \n                    x\n                  \n                \n              \n            \n            \n              \n              \n                \n                ≤\n                \n                  \n                    \n                      2\n                      \n                        −\n                        m\n                        +\n                        k\n                      \n                    \n                    \n                      x\n                      \n                        b\n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      2\n                      \n                        −\n                        m\n                        +\n                        k\n                      \n                    \n                    \n                      (\n                      1\n                      ⋅\n                      \n                        b\n                        \n                          1\n                        \n                      \n                      \n                        b\n                        \n                          2\n                        \n                      \n                      …\n                      \n                        b\n                        \n                          m\n                        \n                      \n                      \n                        )\n                        \n                          2\n                        \n                      \n                      \n                        2\n                        \n                          k\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                =\n                \n                  \n                    \n                      2\n                      \n                        −\n                        m\n                      \n                    \n                    \n                      (\n                      1\n                      ⋅\n                      \n                        b\n                        \n                          1\n                        \n                      \n                      \n                        b\n                        \n                          2\n                        \n                      \n                      …\n                      \n                        b\n                        \n                          m\n                        \n                      \n                      \n                        )\n                        \n                          2\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n              \n                \n                ≤\n                \n                  2\n                  \n                    −\n                    m\n                  \n                \n                =\n                \n                  ε\n                  \n                    mach\n                  \n                \n                .\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\begin{aligned}\\left|{\\frac {x-y}{x}}\\right|&\\leq {\\frac {2^{-m+k}}{x}}\\\\&\\leq {\\frac {2^{-m+k}}{x_{b}}}\\\\&={\\frac {2^{-m+k}}{(1\\cdot b_{1}b_{2}\\ldots b_{m})_{2}2^{k}}}\\\\&={\\frac {2^{-m}}{(1\\cdot b_{1}b_{2}\\ldots b_{m})_{2}}}\\\\&\\leq 2^{-m}=\\varepsilon _{\\text{mach}}.\\end{aligned}}}\n  \n\nAlthough this proof is limited to positive numbers and round-by-chop, the same method can be used to prove the inequality in relation to negative numbers and round-to-nearest machine representations.\n\nSee also\nFloating point, general discussion of accuracy issues in floating point arithmetic\nUnit in the last place (ULP)\n\nNotes and references\nExternal links\nMACHAR, a routine (in C and Fortran) to \"dynamically compute machine constants\" (ACM algorithm 722)\nDiagnosing floating point calculations precision, Implementation of MACHAR in Component Pascal and Oberon based on the Fortran 77 version of MACHAR published in Numerical Recipes (Press et al., 1992).\n",
  "categories": [
    "Category:Articles with example C code",
    "Category:Articles with example Python (programming language) code",
    "Category:Articles with short description",
    "Category:Computer arithmetic",
    "Category:Short description is different from Wikidata",
    "Category:Wikipedia articles needing clarification from March 2021"
  ],
  "archived_date": "20241221_183019",
  "source_url": "https://en.wikipedia.org/wiki/Machine_epsilon"
}