{
  "title": "Apache Avro",
  "summary": "Avro is a row-oriented remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format. Its primary use is in Apache Hadoop, where it can provide both a serialization format for persistent data, and a wire format for communication between Hadoop nodes, and from client programs to the Hadoop services.\nAvro uses a schema to structure the data that is being encoded. It",
  "content": "---\ntitle: Apache Avro\nurl: https://en.wikipedia.org/wiki/Apache_Avro\nlanguage: en\ncategories: [\"Category:Apache Software Foundation projects\", \"Category:Application layer protocols\", \"Category:Articles with example Python (programming language) code\", \"Category:Articles with short description\", \"Category:Data serialization formats\", \"Category:Inter-process communication\", \"Category:Remote procedure call\", \"Category:Short description is different from Wikidata\", \"Category:Use mdy dates from April 2016\"]\nreferences: 0\nlast_modified: 2024-12-19T14:22:10Z\n---\n\n# Apache Avro\n\n## Summary\n\nAvro is a row-oriented remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format. Its primary use is in Apache Hadoop, where it can provide both a serialization format for persistent data, and a wire format for communication between Hadoop nodes, and from client programs to the Hadoop services.\nAvro uses a schema to structure the data that is being encoded. It\n\n## Full Content\n\nAvro is a row-oriented remote procedure call and data serialization framework developed within Apache's Hadoop project. It uses JSON for defining data types and protocols, and serializes data in a compact binary format. Its primary use is in Apache Hadoop, where it can provide both a serialization format for persistent data, and a wire format for communication between Hadoop nodes, and from client programs to the Hadoop services.\nAvro uses a schema to structure the data that is being encoded. It has two different types of schema languages: one for human editing (Avro IDL) and another which is more machine-readable based on JSON.\nIt is similar to Thrift and Protocol Buffers, but does not require running a code-generation program when a schema changes (unless desired for statically-typed languages).\nApache Spark SQL can access Avro as a data source.\n\nAvro Object Container File\nAn Avro Object Container File consists of: \n\nA file header, followed by\none or more file data blocks.\nA file header consists of:\n\nFour bytes, ASCII 'O', 'b', 'j', followed by the Avro version number which is 1 (0x01) (Binary values 0x4F 0x62 0x6A 0x01).\nFile metadata, including the schema definition.\nThe 16-byte, randomly-generated sync marker for this file.\nFor data blocks Avro specifies two serialization encodings: binary and JSON. Most applications will use the binary encoding, as it is smaller and faster.  For debugging and web-based applications, the JSON encoding may sometimes be appropriate.\n\nSchema definition\nAvro schemas are defined using JSON.  Schemas are composed of primitive types (null, boolean, int, long, float, double, bytes, and string) and complex types (record, enum, array, map, union, and fixed).\nSimple schema example:\n\nSerializing and deserializing\nData in Avro might be stored with its corresponding schema, meaning a serialized item can be read without knowing the schema ahead of time.\n\nExample serialization and deserialization code in Python\nSerialization:\n\nFile \"users.avro\" will contain the schema in JSON and a compact binary representation of the data:\n\nDeserialization:\n\nThis outputs:\n\nLanguages with APIs\nThough theoretically any language could use Avro, the following languages have APIs written for them:\n\nC\nC++\nC#\nElixir\nGo\nHaskell\nJava\nJavascript\nPerl\nPHP\nPython\nRuby\nRust\nScala\n\nAvro IDL\nIn addition to supporting JSON for type and protocol definitions, Avro includes experimental support for an alternative interface description language (IDL) syntax known as Avro IDL.  Previously known as GenAvro, this format is designed to ease adoption by users familiar with more traditional IDLs and programming languages, with a syntax similar to C/C++, Protocol Buffers and others.\n\nLogo\nThe original Apache Avro logo was from the defunct British aircraft manufacturer Avro (originally A.V. Roe and Company).\nThe Apache Avro logo was updated to an original design in late 2023.\n\nSee also\nComparison of data serialization formats\nApache Thrift\nProtocol Buffers\nEtch (protocol)\nInternet Communications Engine\nMessagePack\nCBOR\n\nReferences\nFurther reading\nWhite, Tom (November 2010). Hadoop: The Definitive Guide. ISBN 978-1-4493-8973-4.\n",
  "categories": [
    "Category:Apache Software Foundation projects",
    "Category:Application layer protocols",
    "Category:Articles with example Python (programming language) code",
    "Category:Articles with short description",
    "Category:Data serialization formats",
    "Category:Inter-process communication",
    "Category:Remote procedure call",
    "Category:Short description is different from Wikidata",
    "Category:Use mdy dates from April 2016"
  ],
  "archived_date": "20241220_214801",
  "source_url": "https://en.wikipedia.org/wiki/Apache_Avro"
}