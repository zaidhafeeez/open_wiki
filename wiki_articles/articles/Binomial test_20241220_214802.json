{
  "title": "Binomial test",
  "summary": "Binomial test is an exact test of the statistical significance of deviations from a theoretically expected distribution of observations into two categories using sample data.",
  "content": "---\ntitle: Binomial test\nurl: https://en.wikipedia.org/wiki/Binomial_test\nlanguage: en\ncategories: [\"Category:All articles needing additional references\", \"Category:Articles needing additional references from November 2016\", \"Category:Articles with example Java code\", \"Category:Articles with example MATLAB/Octave code\", \"Category:Articles with example Python (programming language) code\", \"Category:Articles with example R code\", \"Category:Articles with short description\", \"Category:Short description is different from Wikidata\", \"Category:Statistical tests\"]\nreferences: 0\nlast_modified: 2024-12-19T13:46:04Z\n---\n\n# Binomial test\n\n## Summary\n\nBinomial test is an exact test of the statistical significance of deviations from a theoretically expected distribution of observations into two categories using sample data.\n\n## Full Content\n\nBinomial test is an exact test of the statistical significance of deviations from a theoretically expected distribution of observations into two categories using sample data.\n\nUsage\nThe binomial test is useful to test hypotheses about the probability (\n  \n    \n      \n        π\n      \n    \n    {\\displaystyle \\pi }\n  \n) of success:\n\n  \n    \n      \n        \n          H\n          \n            0\n          \n        \n        :\n        π\n        =\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle H_{0}\\colon \\pi =\\pi _{0}}\n  \n\nwhere \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi _{0}}\n  \n is a user-defined value between 0 and 1.\nIf in a sample of size \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n there are \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n successes, while we expect \n  \n    \n      \n        n\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle n\\pi _{0}}\n  \n, the formula of the binomial distribution gives the probability of finding this value:\n\n  \n    \n      \n        Pr\n        (\n        X\n        =\n        k\n        )\n        =\n        \n          \n            \n              (\n            \n            \n              n\n              k\n            \n            \n              )\n            \n          \n        \n        \n          p\n          \n            k\n          \n        \n        (\n        1\n        −\n        p\n        \n          )\n          \n            n\n            −\n            k\n          \n        \n      \n    \n    {\\displaystyle \\Pr(X=k)={\\binom {n}{k}}p^{k}(1-p)^{n-k}}\n  \n\nIf the null hypothesis \n  \n    \n      \n        \n          H\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle H_{0}}\n  \n were correct, then the expected number of successes would be \n  \n    \n      \n        n\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle n\\pi _{0}}\n  \n. We find our \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-value for this test by considering the probability of seeing an outcome as, or more, extreme. For a one-tailed test, this is straightforward to compute. Suppose that we want to test if \n  \n    \n      \n        π\n        <\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi <\\pi _{0}}\n  \n. Then our \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-value would be,\n\n  \n    \n      \n        p\n        =\n        \n          ∑\n          \n            i\n            =\n            0\n          \n          \n            k\n          \n        \n        Pr\n        (\n        X\n        =\n        i\n        )\n        =\n        \n          ∑\n          \n            i\n            =\n            0\n          \n          \n            k\n          \n        \n        \n          \n            \n              (\n            \n            \n              n\n              i\n            \n            \n              )\n            \n          \n        \n        \n          π\n          \n            0\n          \n          \n            i\n          \n        \n        (\n        1\n        −\n        \n          π\n          \n            0\n          \n        \n        \n          )\n          \n            n\n            −\n            i\n          \n        \n      \n    \n    {\\displaystyle p=\\sum _{i=0}^{k}\\Pr(X=i)=\\sum _{i=0}^{k}{\\binom {n}{i}}\\pi _{0}^{i}(1-\\pi _{0})^{n-i}}\n  \n\nAn analogous computation can be done if we're testing if \n  \n    \n      \n        π\n        >\n        \n          π\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle \\pi >\\pi _{0}}\n  \n using the summation of the range from \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n to \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n instead.\nCalculating a \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-value for a two-tailed test is slightly more complicated, since a binomial distribution isn't symmetric if \n  \n    \n      \n        \n          π\n          \n            0\n          \n        \n        ≠\n        0.5\n      \n    \n    {\\displaystyle \\pi _{0}\\neq 0.5}\n  \n. This means that we can't just double the \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-value from the one-tailed test. Recall that we want to consider events that are as, or more, extreme than the one we've seen, so we should consider the probability that we would see an event that is as, or less, likely than \n  \n    \n      \n        X\n        =\n        k\n      \n    \n    {\\displaystyle X=k}\n  \n. Let \n  \n    \n      \n        \n          \n            I\n          \n        \n        =\n        {\n        i\n        :\n        Pr\n        (\n        X\n        =\n        i\n        )\n        ≤\n        Pr\n        (\n        X\n        =\n        k\n        )\n        }\n      \n    \n    {\\displaystyle {\\mathcal {I}}=\\{i\\colon \\Pr(X=i)\\leq \\Pr(X=k)\\}}\n  \n denote all such events. Then the two-tailed \n  \n    \n      \n        p\n      \n    \n    {\\displaystyle p}\n  \n-value is calculated as,\n\n  \n    \n      \n        p\n        =\n        \n          ∑\n          \n            i\n            ∈\n            \n              \n                I\n              \n            \n          \n        \n        Pr\n        (\n        X\n        =\n        i\n        )\n        =\n        \n          ∑\n          \n            i\n            ∈\n            \n              \n                I\n              \n            \n          \n        \n        \n          \n            \n              (\n            \n            \n              n\n              i\n            \n            \n              )\n            \n          \n        \n        \n          π\n          \n            0\n          \n          \n            i\n          \n        \n        (\n        1\n        −\n        \n          π\n          \n            0\n          \n        \n        \n          )\n          \n            n\n            −\n            i\n          \n        \n      \n    \n    {\\displaystyle p=\\sum _{i\\in {\\mathcal {I}}}\\Pr(X=i)=\\sum _{i\\in {\\mathcal {I}}}{\\binom {n}{i}}\\pi _{0}^{i}(1-\\pi _{0})^{n-i}}\n\nCommon use\nOne common use of the binomial test is the case where the null hypothesizes that two categories occur with equal frequency (\n  \n    \n      \n        \n          H\n          \n            0\n          \n        \n        :\n        π\n        =\n        0.5\n      \n    \n    {\\displaystyle H_{0}\\colon \\pi =0.5}\n  \n), such as a coin toss. Tables are widely available to give the significance observed numbers of observations in the categories for this case. However, as the example below shows, the binomial test is not restricted to this case.\nWhen there are more than two categories, and an exact test is required, the multinomial test, based on the multinomial distribution, must be used instead of the binomial test.\nMost common measures of effect size for Binomial tests are Cohen's h or Cohen's g.\n\nLarge samples\nFor large samples such as the example below, the binomial distribution is well approximated by convenient continuous distributions, and these are used as the basis for alternative tests that are much quicker to compute, such as Pearson's chi-squared test and the G-test.  However, for small samples these approximations break down, and there is no alternative to the binomial test.\nThe most usual (and easiest) approximation is through the standard normal distribution, in which a z-test is performed of the test statistic \n  \n    \n      \n        Z\n      \n    \n    {\\displaystyle Z}\n  \n, given by\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              k\n              −\n              n\n              π\n            \n            \n              n\n              π\n              (\n              1\n              −\n              π\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle Z={\\frac {k-n\\pi }{\\sqrt {n\\pi (1-\\pi )}}}}\n  \n\nwhere \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n  \n is the number of successes observed in a sample of size \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n and \n  \n    \n      \n        π\n      \n    \n    {\\displaystyle \\pi }\n  \n is the probability of success according to the null hypothesis. An improvement on this approximation is possible by introducing a continuity correction:\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              k\n              −\n              n\n              π\n              ±\n              \n                \n                  1\n                  2\n                \n              \n            \n            \n              n\n              π\n              (\n              1\n              −\n              π\n              )\n            \n          \n        \n      \n    \n    {\\displaystyle Z={\\frac {k-n\\pi \\pm {\\frac {1}{2}}}{\\sqrt {n\\pi (1-\\pi )}}}}\n  \n\nFor very large \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, this continuity correction will be unimportant, but for intermediate values, where the exact binomial test doesn't work, it will yield a substantially more accurate result.\nIn notation in terms of a measured sample proportion \n  \n    \n      \n        \n          \n            \n              p\n              ^\n            \n          \n        \n      \n    \n    {\\displaystyle {\\hat {p}}}\n  \n, null hypothesis for the proportion \n  \n    \n      \n        \n          p\n          \n            0\n          \n        \n      \n    \n    {\\displaystyle p_{0}}\n  \n, and sample size \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n, where \n  \n    \n      \n        \n          \n            \n              p\n              ^\n            \n          \n        \n        =\n        k\n        \n          /\n        \n        n\n      \n    \n    {\\displaystyle {\\hat {p}}=k/n}\n  \n and \n  \n    \n      \n        \n          p\n          \n            0\n          \n        \n        =\n        π\n      \n    \n    {\\displaystyle p_{0}=\\pi }\n  \n, one may rearrange and write the z-test above as\n\n  \n    \n      \n        Z\n        =\n        \n          \n            \n              \n                \n                  \n                    p\n                    ^\n                  \n                \n              \n              −\n              \n                p\n                \n                  0\n                \n              \n            \n            \n              \n                \n                  \n                    p\n                    \n                      0\n                    \n                  \n                  (\n                  1\n                  −\n                  \n                    p\n                    \n                      0\n                    \n                  \n                  )\n                \n                n\n              \n            \n          \n        \n      \n    \n    {\\displaystyle Z={\\frac {{\\hat {p}}-p_{0}}{\\sqrt {\\frac {p_{0}(1-p_{0})}{n}}}}}\n  \n\nby dividing by \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  \n in both numerator and denominator, which is a form that may be more familiar to some readers.\n\nExample\nSuppose we have a board game that depends on the roll of one die and attaches special importance to rolling a 6. In a particular game, the die is rolled 235 times, and 6 comes up 51 times. If the die is fair, we would expect 6 to come up \n\n  \n    \n      \n        235\n        ×\n        1\n        \n          /\n        \n        6\n        =\n        39.17\n      \n    \n    {\\displaystyle 235\\times 1/6=39.17}\n  \n\ntimes. We have now observed that the number of 6s is higher than what we would expect on average by pure chance had the die been a fair one. But, is the number significantly high enough for us to conclude anything about the fairness of the die? This question can be answered by the binomial test. Our null hypothesis would be that the die is fair (probability of each number coming up on the die is 1/6).\nTo find an answer to this question using the binomial test, we use the binomial distribution \n\n  \n    \n      \n        B\n        (\n        N\n        =\n        235\n        ,\n        p\n        =\n        1\n        \n          /\n        \n        6\n        )\n      \n    \n    {\\displaystyle B(N=235,p=1/6)}\n  \n  with pmf \n  \n    \n      \n        f\n        (\n        k\n        ,\n        n\n        ,\n        p\n        )\n        =\n        Pr\n        (\n        k\n        ;\n        n\n        ,\n        p\n        )\n        =\n        Pr\n        (\n        X\n        =\n        k\n        )\n        =\n        \n          \n            \n              (\n            \n            \n              n\n              k\n            \n            \n              )\n            \n          \n        \n        \n          p\n          \n            k\n          \n        \n        (\n        1\n        −\n        p\n        \n          )\n          \n            n\n            −\n            k\n          \n        \n      \n    \n    {\\displaystyle f(k,n,p)=\\Pr(k;n,p)=\\Pr(X=k)={\\binom {n}{k}}p^{k}(1-p)^{n-k}}\n  \n .\nAs we have observed a value greater than the expected value, we could consider the probability of observing 51 6s or higher under the null, which would constitute a one-tailed test (here we are basically testing whether this die is biased towards generating more 6s than expected). In order to calculate the probability of 51 or more 6s in a sample of 235 under the null hypothesis we add up the probabilities of getting exactly 51 6s, exactly 52 6s, and so on up to probability of getting exactly 235 6s:\n\n  \n    \n      \n        \n          ∑\n          \n            i\n            =\n            51\n          \n          \n            235\n          \n        \n        \n          \n            \n              (\n            \n            \n              235\n              i\n            \n            \n              )\n            \n          \n        \n        \n          p\n          \n            i\n          \n        \n        (\n        1\n        −\n        p\n        \n          )\n          \n            235\n            −\n            i\n          \n        \n        =\n        0.02654\n      \n    \n    {\\displaystyle \\sum _{i=51}^{235}{235 \\choose i}p^{i}(1-p)^{235-i}=0.02654}\n  \n\nIf we have a significance level of 5%, then this result (0.02654 < 5%) indicates that we have evidence that is significant enough to reject the null hypothesis that the die is fair.\nNormally, when we are testing for fairness of a die, we are also interested if the die is biased towards generating fewer 6s than expected, and not only more 6s as we considered in the one-tailed test above. In order to consider both the biases, we use a two-tailed test. Note that to do this we cannot simply double the one-tailed p-value unless the probability of the event is 1/2. This is because the binomial distribution becomes asymmetric as that probability deviates from 1/2. There are two methods to define the two-tailed p-value. One method is to sum the probability that the total deviation in numbers of events in either direction from the expected value is either more than or less than the expected value. The probability of that occurring in our example is 0.0437. The second method involves computing the probability that the deviation from the expected value is as unlikely or more unlikely than the observed value, i.e. from a comparison of the probability density functions. This can create a subtle difference, but in this example yields the same probability of 0.0437. In both cases, the two-tailed test reveals significance at the 5% level, indicating that the number of 6s observed was significantly different for this die than the expected number at the 5% level.\n\nIn statistical software packages\nBinomial tests are available in most software used for statistical purposes. E.g.\n\nIn R the above example could be calculated with the following code:\nbinom.test(51, 235, 1/6, alternative = \"less\") (one-tailed test)\nbinom.test(51, 235, 1/6, alternative = \"greater\") (one-tailed test)\nbinom.test(51, 235, 1/6, alternative = \"two.sided\") (two-tailed test)\nIn Java using the Apache Commons library:\nnew BinomialTest().binomialTest(235, 51, 1.0 / 6, AlternativeHypothesis.LESS_THAN) (one-tailed test)\nnew BinomialTest().binomialTest(235, 51, 1.0 / 6, AlternativeHypothesis.GREATER_THAN) (one-tailed test)\nnew BinomialTest().binomialTest(235, 51, 1.0 / 6, AlternativeHypothesis.TWO_SIDED) (two-tailed test)\nIn SAS the test is available in the Frequency procedure\nIn SPSS the test can be utilized through the menu Analyze > Nonparametric test > Binomial\nIn Python, use SciPy's binomtest:\nscipy.stats.binomtest(51, 235, 1.0/6, alternative='greater') (one-tailed test)\nscipy.stats.binomtest(51, 235, 1.0/6, alternative='two-sided') (two-tailed test)\nIn MATLAB, use myBinomTest, which is available via Mathworks' community File Exchange website. myBinomTest will directly calculate the p-value for the observations given the hypothesized probability of a success. [pout]=myBinomTest(51, 235, 1/6) (generally two-tailed, but can optionally perform a one-tailed test).\nIn Stata, use bitest.\nIn Microsoft Excel, use Binom.Dist. The function takes parameters (Number of successes, Trials, Probability of Success, Cumulative).  The \"Cumulative\" parameter takes a boolean True or False, with True giving the Cumulative probability of finding this many successes (a left-tailed test), and False the exact probability of finding this many successes.\n\nSee also\np-value\nCohen's g\nCohen's h\n Lady tasting tea experiment\n\nReferences\nFurther reading\nDougherty, Edward R. (1990). \"Testing a Proportion\". Probability and Statistics for the Engineering, Computing, and Physical Sciences. Englewood Cliffs: Prentice Hall. pp. 417–423. ISBN 0-13-711995-X.\n\nExternal links\nBinomial Probability Calculator\n\"The binomial test\". www.graphpad.com.\n",
  "categories": [
    "Category:All articles needing additional references",
    "Category:Articles needing additional references from November 2016",
    "Category:Articles with example Java code",
    "Category:Articles with example MATLAB/Octave code",
    "Category:Articles with example Python (programming language) code",
    "Category:Articles with example R code",
    "Category:Articles with short description",
    "Category:Short description is different from Wikidata",
    "Category:Statistical tests"
  ],
  "archived_date": "20241220_214802",
  "source_url": "https://en.wikipedia.org/wiki/Binomial_test"
}